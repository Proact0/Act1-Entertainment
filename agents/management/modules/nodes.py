"""
ì¸ìŠ¤íƒ€ê·¸ë¨ API ì›Œí¬í”Œë¡œìš°ë¥¼ ìœ„í•œ ë…¸ë“œ í´ë˜ìŠ¤ ëª¨ë“ˆ

í•´ë‹¹ í´ë˜ìŠ¤ ëª¨ë“ˆì€ ê°ê° ë…¸ë“œ í´ë˜ìŠ¤ê°€ BaseNodeë¥¼ ìƒì†ë°›ì•„ ë…¸ë“œ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
"""

import json
import os
import requests
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv
from datetime import datetime
from pydantic import BaseModel, Field
import sys

# Add the project root to sys.path to resolve module import issues for internal modules
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", ".."))
sys.path.append(project_root)

from agents.base_node import BaseNode
from agents.management.modules.state import ManagementState
from agents.management.modules.prompts import get_instagram_comment_analysis_prompt, get_instagram_analysis_report_prompt

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from langchain_core.utils.function_calling import convert_to_openai_tool

load_dotenv(override=True)

class CommentAnalysis(BaseModel):
    """A single analyzed Instagram comment."""
    comment: str = Field(description="The original comment text.")
    sentiment: str = Field(description="Sentiment of the comment (e.g., 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½').")
    comment_type: str = Field(description="Type of the comment (e.g., 'íŒ¬ëŒ“ê¸€', 'ì§ˆë¬¸', 'ë¹„íŒ').")
    reply_needed: str = Field(description="Whether a reply is needed ('ì˜ˆ', 'ì•„ë‹ˆì˜¤', 'ê³ ë ¤').")
    reason: str = Field(description="Reason for the sentiment, type, and reply_needed assessment.")

class InstagramCommentsAnalysisOutput(BaseModel):
    """The structured output for Instagram comment analysis."""
    comments: List[CommentAnalysis] = Field(description="A list of analyzed Instagram comments.")

class InstagramAnalysisReportOutput(BaseModel):
    """The structured output for an Instagram comments analysis report."""
    report_date: str = Field(description="The date the report was generated (YYYY-MM-DD-HH-MM).")
    total_comments_analyzed: int = Field(description="Total number of comments analyzed.")
    summary: str = Field(description="A comprehensive summary of the Instagram comments analysis.")
    key_insights: List[str] = Field(description="Key insights derived from the comment analysis, e.g., trends, recurring themes.")
    sentiment_distribution: Dict[str, int] = Field(description="Distribution of sentiments (e.g., {'ê¸ì •': X, 'ë¶€ì •': Y, 'ì¤‘ë¦½': Z}).")
    comment_type_distribution: Dict[str, int] = Field(description="Distribution of comment types (e.g., {'íŒ¬ëŒ“ê¸€': A, 'ì§ˆë¬¸': B, 'ë¹„íŒ': C, 'ê¸°íƒ€': D}).")
    reply_needed_breakdown: Dict[str, int] = Field(description="Breakdown of comments needing a reply (e.g., {'ì˜ˆ': E, 'ì•„ë‹ˆì˜¤': F, 'ê³ ë ¤': G}).")
    action_items: List[str] = Field(description="Actionable recommendations for community management based on the analysis.")

class InstagramMediaFetchNode(BaseNode):
    """
    ì¸ìŠ¤íƒ€ê·¸ë¨ ë¯¸ë””ì–´ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë…¸ë“œ
    """

    def execute(self, state: ManagementState) -> Dict[str, Any]:
        """
        ì¸ìŠ¤íƒ€ê·¸ë¨ APIë¥¼ í†µí•´ ë¯¸ë””ì–´ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê±°ë‚˜ JSON íŒŒì¼ì—ì„œ ì½ì–´ì˜µë‹ˆë‹¤.
        ëŒ“ê¸€ ìˆ˜ ë³€ê²½ì„ ê°ì§€í•˜ê³  ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ” [InstagramMediaFetchNode] ì‹¤í–‰ ì¤‘...")
        
        json_file_path = state["comment_file_path"]
        access_token = state["access_token"]
        user_id = state["user_id"]
        
        # JSON íŒŒì¼ì—ì„œ ì´ì „ ë°ì´í„° ì½ê¸°
        previous_data = None
        if os.path.exists(json_file_path):
            try:
                with open(json_file_path, 'r', encoding='utf-8') as f:
                    previous_data = json.load(f)
                print(f"ğŸ“ [InstagramMediaFetchNode] JSON íŒŒì¼ì—ì„œ ì´ì „ ë°ì´í„°ë¥¼ ì½ì–´ì™”ìŠµë‹ˆë‹¤.")
                # print(f"first_media_id: {previous_data['first_media_id']} / previous_comments_count: {previous_data['previous_comments_count']}")
            except Exception as e:
                print(f"JSON íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
        
        # Instagram APIì—ì„œ ìµœì‹  ë¯¸ë””ì–´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        print(f"ğŸ“¡ [InstagramMediaFetchNode] Instagram APIì—ì„œ ë¯¸ë””ì–´ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
        
        # ìš”ì²­í•  í•„ë“œ ì§€ì •
        fields = 'id,caption,media_type,timestamp,username,like_count,comments_count'
        
        url = f'https://graph.instagram.com/v23.0/{user_id}/media?access_token={access_token}'
        params = {
            'fields': fields,
        }
        
        try:
            response = requests.get(url, params=params)
            if response.status_code == 200:
                data = response.json()
                media_data = data.get('data', [])
                
                if not media_data:
                    return {
                        "response": "ë¯¸ë””ì–´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                    }
                
                # ì²« ë²ˆì§¸ ë¯¸ë””ì–´ ì •ë³´
                first_media = media_data[0]
                first_media_id = first_media['id']
                current_comments_count = first_media['comments_count']
                
                print(f"ğŸ“Š [InstagramMediaFetchNode] ì²« ë²ˆì§¸ ë¯¸ë””ì–´ {first_media_id}ì˜ ëŒ“ê¸€ ìˆ˜: {current_comments_count}")
                
                # ì´ì „ ë°ì´í„°ì™€ ë¹„êµ
                has_changes = False
                previous_comments_count = 0
                
                if previous_data:
                    previous_comments_count = previous_data.get('previous_comments_count', 0)
                    has_changes = current_comments_count != previous_comments_count
                    print(f"ğŸ“Š [InstagramMediaFetchNode] ì´ì „ ëŒ“ê¸€ ìˆ˜: {previous_comments_count}, í˜„ì¬: {current_comments_count}, ë³€ê²½: {has_changes}")
                
                # ëŒ“ê¸€ ìˆ˜ ë³€ê²½ì´ ìˆì„ ë•ŒëŠ” JSON íŒŒì¼ì„ ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸í•˜ë„ë¡ ì„ì‹œ ë°ì´í„°ë§Œ ì¤€ë¹„
                json_data = {
                    'media_data': media_data,
                    'first_media_id': first_media_id,
                    'previous_comments_count': current_comments_count
                }
                
                # ìµœì´ˆ ì‹¤í–‰, ëŒ“ê¸€ ìˆ˜ ë³€ê²½ì´ ìˆì„ ë•Œë§Œ JSON íŒŒì¼ ì—…ë°ì´íŠ¸
                if not os.path.exists(json_file_path):
                    with open(json_file_path, 'w', encoding='utf-8') as f:
                        json.dump(json_data, f, ensure_ascii=False, indent=2)
                    print(f"ğŸ’¾ [InstagramMediaFetchNode] ìµœì´ˆ ì‹¤í–‰: ë¯¸ë””ì–´ ë°ì´í„°ë¥¼ JSON íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                else:
                    if has_changes:
                        print(f"ğŸ“ [InstagramMediaFetchNode] ëŒ“ê¸€ ìˆ˜ ë³€ê²½ ê°ì§€. JSON íŒŒì¼ì€ ëŒ“ê¸€ ìˆ˜ì§‘ í›„ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.")
                    else:
                        print(f"ğŸ“ [InstagramMediaFetchNode] ê¸°ì¡´ JSON íŒŒì¼ì´ ì¡´ì¬í•˜ì—¬ ì €ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
                
                return {
                    "media_data": media_data,
                    "first_media_id": first_media_id,
                    "current_comments_count": current_comments_count,
                    "previous_comments_count": previous_comments_count,
                    "has_changes": has_changes,
                    "json_data": json_data,  # ëŒ“ê¸€ ìˆ˜ì§‘ í›„ ì €ì¥í•  ë°ì´í„°
                    "response": f"ë¯¸ë””ì–´ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ì´ {len(media_data)}ê°œì˜ í¬ìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤. ëŒ“ê¸€ ìˆ˜ ë³€ê²½: {has_changes}"
                }
            else:
                return {
                    "response": f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code} - {response.text}"
                }
        except Exception as e:
            return {
                "response": f"ë¯¸ë””ì–´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }


class InstagramCommentsFetchNode(BaseNode):
    """
    ëŒ“ê¸€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë…¸ë“œ
    """

    def execute(self, state: ManagementState) -> Dict[str, Any]:
        """
        ì²« ë²ˆì§¸ ë¯¸ë””ì–´ì˜ ëŒ“ê¸€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        """
        print(f"ğŸ” [InstagramCommentsFetchNode] ì‹¤í–‰ ì¤‘...")
        
        access_token = state["access_token"]
        first_media_id = state["first_media_id"]
        json_file_path = state["comment_file_path"]
        json_data = state.get("json_data")
        
        if not first_media_id:
            return {
                "response": "ë¯¸ë””ì–´ IDê°€ ì—†ìŠµë‹ˆë‹¤."
            }
        
        try:
            # ëŒ“ê¸€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            comments_data = self._get_comments_data(access_token, first_media_id)
            
            # ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥
            print(f"\nğŸ“ [InstagramCommentsFetchNode] ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸:")
            for i, comment in enumerate(comments_data, 1):
                print(f"  {i}. {comment.get('text', 'N/A')} (by {comment.get('username', 'Unknown')})")
            print()
            
            # ëŒ“ê¸€ ìˆ˜ì§‘ í›„ JSON íŒŒì¼ ì €ì¥
            if json_data:
                # media_dataì˜ ì²« ë²ˆì§¸ í•­ëª©ì˜ comments_count ì—…ë°ì´íŠ¸
                if json_data.get('media_data') and len(json_data['media_data']) > 0:
                    json_data['media_data'][0]['comments_count'] = state.get('current_comments_count', 0)
                
                # previous_comments_count ì—…ë°ì´íŠ¸
                json_data['previous_comments_count'] = state.get('current_comments_count', 0)
                
                with open(json_file_path, 'w', encoding='utf-8') as f:
                    json.dump(json_data, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ [InstagramCommentsFetchNode] ëŒ“ê¸€ ìˆ˜ì§‘ ì™„ë£Œ í›„ JSON íŒŒì¼ì„ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
            
            return {
                "comments_data": comments_data,
                "response": f"ëŒ“ê¸€ ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤. ì´ {len(comments_data)}ê°œì˜ ëŒ“ê¸€ì´ ìˆìŠµë‹ˆë‹¤."
            }
        except Exception as e:
            return {
                "response": f"ëŒ“ê¸€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }
    
    def _get_comments_data(self, access_token: str, media_id: str) -> List[Dict[str, Any]]:
        """
        Get comments APIë¥¼ í†µí•´ íŠ¹ì • ë¯¸ë””ì–´ì˜ ëŒ“ê¸€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        """
        url = f'https://graph.instagram.com/v23.0/{media_id}/comments?access_token={access_token}'
        params = {
            'fields': 'id,text,timestamp,username'
        }
        
        try:
            response = requests.get(url, params=params)
            if response.status_code == 200:
                data = response.json()
                comments = data.get('data', [])
                print(f"ğŸ“ [InstagramCommentsFetchNode] ë¯¸ë””ì–´ {media_id}ì—ì„œ {len(comments)}ê°œì˜ ëŒ“ê¸€ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                return comments
            else:
                print(f"ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° API ì˜¤ë¥˜: {response.status_code} - {response.text}")
                return []
        except Exception as e:
            print(f"ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {str(e)}")
            return []


class InstagramCommentsAnalysisNode(BaseNode):
    """
    ì¸ìŠ¤íƒ€ê·¸ë¨ ëŒ“ê¸€ì„ LLM(Gemini)ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ë…¸ë“œ (langchain ê¸°ë°˜)
    """
    def execute(self, state: ManagementState) -> Dict[str, Any]:
        print(f"ğŸ” [InstagramCommentsAnalysisNode] ì‹¤í–‰ ì¤‘...")
        comments_data = state.get("comments_data", [])
        if not comments_data:
            return {"response": "ë¶„ì„í•  ëŒ“ê¸€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # ëŒ“ê¸€ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        comments_texts = [c.get("text", "") for c in comments_data if c.get("text")]
        comments_str = "\n".join(comments_texts)

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_template = get_instagram_comment_analysis_prompt()
        prompt = prompt_template.format(comments=comments_str)

        try:
            api_key = state.get("api_key","")
            if not api_key:
                return {"response": "GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.", "comment_analysis_result": None}

            llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key)
            # Bind the Pydantic model as a tool
            response = llm.invoke(prompt)
            print(f"LLM Raw Response: {response.content}")

            # Parse the raw JSON string output from the LLM
            try:
                json_content = response.content
                # Remove markdown code block fences if present
                if json_content.startswith('```json') and json_content.endswith('```'):
                    json_content = json_content[len('```json'):-len('```')].strip()
                
                # Using .model_validate_json for Pydantic v2
                parsed_output = InstagramCommentsAnalysisOutput.model_validate_json(json_content)
            except Exception as parse_error:
                raise ValueError(f"Failed to parse LLM response as JSON: {parse_error}\nRaw content: {response.content}")

            analysis_result_dict = parsed_output.model_dump()

            print(f"[InstagramCommentsAnalysisNode] ë¶„ì„ ê²°ê³¼:\n{json.dumps(analysis_result_dict, ensure_ascii=False, indent=2)}")
            state["comment_analysis_result"] = analysis_result_dict
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ ë³„ë„ json íŒŒì¼ë¡œ ì €ì¥
            now_str = datetime.now().isoformat()
            analysis_file_path = state.get("comment_analysis_file_path")
            
            if os.path.exists(analysis_file_path):
                try:
                    with open(analysis_file_path, 'r', encoding='utf-8') as f:
                        analysis_data = json.load(f)
                except Exception:
                    analysis_data = {}
                analysis_data[now_str] = analysis_result_dict
            else:
                # Ensure the directory exists before writing the file
                os.makedirs(os.path.dirname(analysis_file_path), exist_ok=True)
                analysis_data = {now_str: analysis_result_dict}
            
            with open(analysis_file_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2, separators=(',', ': '))
            print(f"[InstagramCommentsAnalysisNode] ë¶„ì„ ê²°ê³¼ë¥¼ {analysis_file_path}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            return {"comment_analysis_result": analysis_result_dict, "response": "ëŒ“ê¸€ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."}
        except Exception as e:
            print(f"[InstagramCommentsAnalysisNode] Gemini í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            return {"response": f"Gemini í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}", "comment_analysis_result": None}


class NoChangeNode(BaseNode):
    """
    ëŒ“ê¸€ ìˆ˜ ë³€ê²½ì´ ì—†ì„ ë•Œ ì‹¤í–‰ë˜ëŠ” ë…¸ë“œ
    """

    def execute(self, state: ManagementState) -> Dict[str, Any]:
        """
        ëŒ“ê¸€ ìˆ˜ ë³€ê²½ì´ ì—†ì„ ë•Œì˜ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ” [NoChangeNode] ì‹¤í–‰ ì¤‘...")
        
        return {
            "response": "ëŒ“ê¸€ ìˆ˜ì— ë³€ê²½ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë‹ˆí„°ë§ì„ ê³„ì†í•©ë‹ˆë‹¤."
        }


class InstagramAnalysisReportNode(BaseNode):
    """
    ì¸ìŠ¤íƒ€ê·¸ë¨ ëŒ“ê¸€ ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” ë…¸ë“œ
    """
    def execute(self, state: ManagementState) -> Dict[str, Any]:
        print(f"ğŸ” [InstagramAnalysisReportNode] ì‹¤í–‰ ì¤‘...")
        report_file_path = state.get("analysis_report_file_path")

        # Load analysis data directly from state
        analyzed_data = state.get("comment_analysis_result")
        if not analyzed_data:
            return {"response": "ë¶„ì„ ë°ì´í„°ê°€ ìƒíƒœì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.", "analysis_report": None}
        print(f"ğŸ“ [InstagramAnalysisReportNode] ë¶„ì„ ë°ì´í„°ë¥¼ ìƒíƒœì—ì„œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

        # Prompt LLM for report generation
        prompt_template = get_instagram_analysis_report_prompt()
        prompt = prompt_template.format(analyzed_data=json.dumps(analyzed_data, ensure_ascii=False, indent=2))

        try:
            api_key = state.get("api_key", "")
            if not api_key:
                return {"response": "GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.", "analysis_report": None}

            llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key)
            response = llm.invoke(prompt)
            print(f"LLM Raw Report Response: {response.content}")

            # Parse the raw JSON string output from the LLM
            try:
                json_content = response.content
                if json_content.startswith('```json') and json_content.endswith('```'):
                    json_content = json_content[len('```json'):-len('```')].strip()
                
                parsed_report = InstagramAnalysisReportOutput.model_validate_json(json_content)
            except Exception as parse_error:
                raise ValueError(f"Failed to parse LLM report as JSON: {parse_error}\nRaw content: {response.content}")
            
            report_dict = parsed_report.model_dump()
            report_dict['media_id'] = state.get("user_id","")

            # Save the report to a new JSON file
            os.makedirs(os.path.dirname(report_file_path), exist_ok=True)
            with open(report_file_path, 'w', encoding='utf-8') as f:
                json.dump(report_dict, f, ensure_ascii=False, indent=2, separators=(',', ': '))
            print(f"[InstagramAnalysisReportNode] ë¶„ì„ ë³´ê³ ì„œë¥¼ {report_file_path}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

            return {"analysis_report": report_dict, "response": "ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        except Exception as e:
            print(f"[InstagramAnalysisReportNode] Gemini í˜¸ì¶œ ë˜ëŠ” ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return {"response": f"Gemini í˜¸ì¶œ ë˜ëŠ” ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {str(e)}", "analysis_report": None}


